{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from linear_cca import linear_cca\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "from DeepCCAModels import DeepCCA\n",
    "from main import Solver\n",
    "from utils import load_data, svm_classify\n",
    "try:\n",
    "    import cPickle as thepickle\n",
    "except ImportError:\n",
    "    import _pickle as thepickle\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "loading data ...\n",
      "loading data ...\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Parameters Section\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "\n",
    "# the path to save the final learned features\n",
    "save_to = './new_features.gz'\n",
    "\n",
    "# the size of the new space learned by the model (number of the new features)\n",
    "outdim_size = 10\n",
    "\n",
    "# size of the input for view 1 and view 2\n",
    "input_shape1 = 784\n",
    "input_shape2 = 784\n",
    "\n",
    "# number of layers with nodes in each one\n",
    "layer_sizes1 = [1024, 1024, 1024, outdim_size]\n",
    "layer_sizes2 = [1024, 1024, 1024, outdim_size]\n",
    "\n",
    "# layer_sizes1 = [1024, outdim_size]\n",
    "# layer_sizes2 = [1024, outdim_size]\n",
    "\n",
    "# the parameters for training the network\n",
    "learning_rate = 1e-3\n",
    "epoch_num = 10\n",
    "batch_size = 800\n",
    "\n",
    "# the regularization parameter of the network\n",
    "# seems necessary to avoid the gradient exploding especially when non-saturating activations are used\n",
    "reg_par = 1e-5\n",
    "\n",
    "# specifies if all the singular values should get used to calculate the correlation or just the top outdim_size ones\n",
    "# if one option does not work for a network or dataset, try the other one\n",
    "use_all_singular_values = False\n",
    "\n",
    "# if a linear CCA should get applied on the learned features extracted from the networks\n",
    "# it does not affect the performance on noisy MNIST significantly\n",
    "apply_linear_cca = True\n",
    "# end of parameters section\n",
    "############\n",
    "\n",
    "# Each view is stored in a gzip file separately. They will get downloaded the first time the code gets executed.\n",
    "# Datasets get stored under the datasets folder of user's Keras folder\n",
    "# normally under [Home Folder]/.keras/datasets/\n",
    "data1 = load_data('./noisymnist_view1.gz')\n",
    "data2 = load_data('./noisymnist_view2.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2024-02-02 23:30:02,500 ] - DataParallel(\n",
      "  (module): DeepCCA(\n",
      "    (attention1): SelfAttention(\n",
      "      (query_projection): Linear(in_features=784, out_features=1024, bias=True)\n",
      "      (key_projection): Linear(in_features=784, out_features=1024, bias=True)\n",
      "      (value_projection): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    )\n",
      "    (attention2): SelfAttention(\n",
      "      (query_projection): Linear(in_features=784, out_features=1024, bias=True)\n",
      "      (key_projection): Linear(in_features=784, out_features=1024, bias=True)\n",
      "      (value_projection): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    )\n",
      "    (model1): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (1): Linear(in_features=1024, out_features=10, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (model2): MlpNet(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x Sequential(\n",
      "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (1): Sigmoid()\n",
      "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "          (1): Linear(in_features=1024, out_features=10, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[ INFO : 2024-02-02 23:30:02,501 ] - RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    weight_decay: 1e-05\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is MSE!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2024-02-02 23:30:10,780 ] - Epoch 1: val_loss improved from 10.0000 to 2.7974, saving model to checkpoint.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2024-02-02 23:30:11,577 ] - Epoch 1/10 - time: 8.98 - training_loss: 2.4008 - val_loss: 2.7974\n",
      "[ INFO : 2024-02-02 23:30:18,995 ] - Epoch 2: val_loss improved from 2.7974 to 0.7472, saving model to checkpoint.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ INFO : 2024-02-02 23:30:19,780 ] - Epoch 2/10 - time: 8.20 - training_loss: 1.3480 - val_loss: 0.7472\n",
      "[ INFO : 2024-02-02 23:30:27,053 ] - Epoch 3: val_loss did not improve from 0.7472\n",
      "[ INFO : 2024-02-02 23:30:27,054 ] - Epoch 3/10 - time: 7.27 - training_loss: 1.0167 - val_loss: 16.3302\n",
      "[ INFO : 2024-02-02 23:30:34,291 ] - Epoch 4: val_loss did not improve from 0.7472\n",
      "[ INFO : 2024-02-02 23:30:34,291 ] - Epoch 4/10 - time: 7.24 - training_loss: 0.8365 - val_loss: 61.7502\n",
      "[ INFO : 2024-02-02 23:30:41,617 ] - Epoch 5: val_loss did not improve from 0.7472\n",
      "[ INFO : 2024-02-02 23:30:41,618 ] - Epoch 5/10 - time: 7.33 - training_loss: 0.7019 - val_loss: 49482.5396\n",
      "[ INFO : 2024-02-02 23:30:48,893 ] - Epoch 6: val_loss did not improve from 0.7472\n",
      "[ INFO : 2024-02-02 23:30:48,894 ] - Epoch 6/10 - time: 7.27 - training_loss: 0.6695 - val_loss: 258685397.4063\n",
      "[ INFO : 2024-02-02 23:30:56,159 ] - Epoch 7: val_loss did not improve from 0.7472\n",
      "[ INFO : 2024-02-02 23:30:56,160 ] - Epoch 7/10 - time: 7.27 - training_loss: 0.5757 - val_loss: 82683169.3042\n",
      "[ INFO : 2024-02-02 23:31:03,427 ] - Epoch 8: val_loss did not improve from 0.7472\n",
      "[ INFO : 2024-02-02 23:31:03,428 ] - Epoch 8/10 - time: 7.27 - training_loss: 0.5461 - val_loss: 32177.6728\n",
      "[ INFO : 2024-02-02 23:31:10,618 ] - Epoch 9: val_loss did not improve from 0.7472\n",
      "[ INFO : 2024-02-02 23:31:10,619 ] - Epoch 9/10 - time: 7.19 - training_loss: 0.4945 - val_loss: 54430.6530\n",
      "[ INFO : 2024-02-02 23:31:17,859 ] - Epoch 10: val_loss did not improve from 0.7472\n",
      "[ INFO : 2024-02-02 23:31:17,860 ] - Epoch 10/10 - time: 7.24 - training_loss: 0.4623 - val_loss: 170948393.4291\n",
      "[ INFO : 2024-02-02 23:31:23,061 ] - loss on validation data: 0.6783\n",
      "[ INFO : 2024-02-02 23:31:23,970 ] - loss on test data: 0.8353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CCA started!\n"
     ]
    }
   ],
   "source": [
    "# Building, training, and producing the new features by DCCA\n",
    "model = DeepCCA(layer_sizes1, layer_sizes2, input_shape1,\n",
    "                input_shape2, outdim_size, use_all_singular_values, device=device).double()\n",
    "l_cca = None\n",
    "if apply_linear_cca:\n",
    "    l_cca = linear_cca()\n",
    "solver = Solver(model, l_cca, outdim_size, epoch_num, batch_size,\n",
    "                learning_rate, reg_par,loss_type = 'MSE', device=device)\n",
    "train1, train2 = data1[0][0], data2[0][0]\n",
    "val1, val2 = data1[1][0], data2[1][0]\n",
    "test1, test2 = data1[2][0], data2[2][0]\n",
    "# val1=None\n",
    "# test1=None\n",
    "solver.fit(train1, train2, val1, val2, test1, test2)\n",
    "# TODO: Save linear_cca model if needed\n",
    "\n",
    "set_size = [0, train1.size(0), train1.size(\n",
    "    0) + val1.size(0), train1.size(0) + val1.size(0) + test1.size(0)]\n",
    "loss, outputs = solver.test(torch.cat([train1, val1, test1], dim=0), torch.cat(\n",
    "    [train2, val2, test2], dim=0), apply_linear_cca)\n",
    "# print(outputs.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM...\n",
      "Accuracy on view 1 (validation data) is: 22.939999999999998\n",
      "Accuracy on view 1 (test data) is: 21.16\n"
     ]
    }
   ],
   "source": [
    "new_data = []\n",
    "# print(outputs)\n",
    "for idx in range(3):\n",
    "    new_data.append([outputs[0][set_size[idx]:set_size[idx + 1], :],\n",
    "                     outputs[1][set_size[idx]:set_size[idx + 1], :], data1[idx][1]])\n",
    "# Training and testing of SVM with linear kernel on the view 1 with new features\n",
    "[test_acc, valid_acc] = svm_classify(new_data, C=0.01)\n",
    "print(\"Accuracy on view 1 (validation data) is:\", valid_acc * 100.0)\n",
    "print(\"Accuracy on view 1 (test data) is:\", test_acc*100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM...\n",
      "Accuracy on view 1 (validation data) is: 79.75\n",
      "Accuracy on view 1 (test data) is: 77.83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAttention size = 256; 10 ep; \\ntraining SVM...\\nAccuracy on view 1 (validation data) is: 64.02\\nAccuracy on view 1 (test data) is: 61.19\\n\\n\\nAttention size = 1024; 10 ep\\ntraining SVM...\\nAccuracy on view 1 (validation data) is: 80.2\\nAccuracy on view 1 (test data) is: 76.86\\n\\nAttention size = 1024; 25 ep\\ntraining SVM...\\nAccuracy on view 1 (validation data) is: 79.3\\nAccuracy on view 1 (test data) is: 77.24\\n\\nAttention size = 1024; 10 ep; mse loss\\ntraining SVM...\\nAccuracy on view 1 (validation data) is: 79.29\\nAccuracy on view 1 (test data) is: 77.25\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attention loss\n",
    "new_data = []\n",
    "# print(outputs)\n",
    "for idx in range(3):\n",
    "    new_data.append([outputs[0][set_size[idx]:set_size[idx + 1], :],\n",
    "                     outputs[1][set_size[idx]:set_size[idx + 1], :], data1[idx][1]])\n",
    "# Training and testing of SVM with linear kernel on the view 1 with new features\n",
    "[test_acc, valid_acc] = svm_classify(new_data, C=0.01)\n",
    "print(\"Accuracy on view 1 (validation data) is:\", valid_acc * 100.0)\n",
    "print(\"Accuracy on view 1 (test data) is:\", test_acc*100.0)\n",
    "\n",
    "\"\"\"\n",
    "Attention size = 256; 10 ep; \n",
    "training SVM...\n",
    "Accuracy on view 1 (validation data) is: 64.02\n",
    "Accuracy on view 1 (test data) is: 61.19\n",
    "\n",
    "\n",
    "Attention size = 1024; 10 ep\n",
    "training SVM...\n",
    "Accuracy on view 1 (validation data) is: 80.2\n",
    "Accuracy on view 1 (test data) is: 76.86\n",
    "\n",
    "Attention size = 1024; 25 ep\n",
    "training SVM...\n",
    "Accuracy on view 1 (validation data) is: 79.3\n",
    "Accuracy on view 1 (test data) is: 77.24\n",
    "\n",
    "Attention size = 1024; 10 ep; mse loss\n",
    "training SVM...\n",
    "Accuracy on view 1 (validation data) is: 79.29\n",
    "Accuracy on view 1 (test data) is: 77.25\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM...\n",
      "Accuracy on view 1 (validation data) is: 95.54\n",
      "Accuracy on view 1 (test data) is: 95.38\n"
     ]
    }
   ],
   "source": [
    "# CCA loss\n",
    "\n",
    "new_data = []\n",
    "# print(outputs)\n",
    "for idx in range(3):\n",
    "    new_data.append([outputs[0][set_size[idx]:set_size[idx + 1], :],\n",
    "                     outputs[1][set_size[idx]:set_size[idx + 1], :], data1[idx][1]])\n",
    "# Training and testing of SVM with linear kernel on the view 1 with new features\n",
    "[test_acc, valid_acc] = svm_classify(new_data, C=0.01)\n",
    "print(\"Accuracy on view 1 (validation data) is:\", valid_acc * 100.0)\n",
    "print(\"Accuracy on view 1 (test data) is:\", test_acc*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM...\n",
      "Accuracy on view 1 (validation data) is: 95.61\n",
      "Accuracy on view 1 (test data) is: 95.1\n"
     ]
    }
   ],
   "source": [
    "# REFERENCE OUTPUT ################\n",
    "#####################################\n",
    "####### DON\"T RUN ##################\n",
    "new_data = []\n",
    "# print(outputs)\n",
    "for idx in range(3):\n",
    "    new_data.append([outputs[0][set_size[idx]:set_size[idx + 1], :],\n",
    "                     outputs[1][set_size[idx]:set_size[idx + 1], :], data1[idx][1]])\n",
    "# Training and testing of SVM with linear kernel on the view 1 with new features\n",
    "[test_acc, valid_acc] = svm_classify(new_data, C=0.01)\n",
    "print(\"Accuracy on view 1 (validation data) is:\", valid_acc * 100.0)\n",
    "print(\"Accuracy on view 1 (test data) is:\", test_acc*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving new features ...\n"
     ]
    }
   ],
   "source": [
    "# Saving new features in a gzip pickled file specified by save_to\n",
    "print('saving new features ...')\n",
    "f1 = gzip.open(save_to, 'wb')\n",
    "thepickle.dump(new_data, f1)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f1aa81e9bd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.load('checkpoint.model')\n",
    "solver.model.load_state_dict(d)\n",
    "solver.model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornet-new",
   "language": "python",
   "name": "cornet-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
